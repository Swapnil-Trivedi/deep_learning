{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f860337",
   "metadata": {},
   "source": [
    "Compare GPT2 and BERT Tokenizers\n",
    "âœ… Task\n",
    "Use HuggingFace to tokenize the same sentence with:\n",
    "\n",
    "GPT-2 tokenizer\n",
    "\n",
    "BERT tokenizer\n",
    "\n",
    "Print:\n",
    "\n",
    "Tokens\n",
    "\n",
    "Token IDs\n",
    "\n",
    "Detokenized version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb69e9a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, BertTokenizer\n",
    "\n",
    "sentence = \"I'm loving neural networks!\"\n",
    "\n",
    "# Tokenize\n",
    "gpt2_tok = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "bert_tok = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Print tokenization\n",
    "print(gpt2_tok.tokenize(sentence))\n",
    "print(bert_tok.tokenize(sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170bdb90",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
