{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4638c804",
   "metadata": {},
   "source": [
    " Implement a Basic Word-Level Tokenizer\n",
    "âœ… Task\n",
    "Create a WordTokenizer class with:\n",
    "\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "class WordTokenizer:\n",
    "    def fit(self, texts): ...\n",
    "    def tokenize(self, text): ...\n",
    "    def convert_tokens_to_ids(self, tokens): ...\n",
    "    def convert_ids_to_tokens(self, ids): ...\n",
    "ðŸ’¡ Bonus\n",
    "Add a special token for <UNK> and <PAD>, and support fixed vocab size (e.g., top 10,000 tokens only)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4f7955",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
